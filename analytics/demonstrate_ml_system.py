"""
ML System Demonstration Script
Shows how models learned from historical data and make predictions
"""

import pandas as pd
import numpy as np
import joblib
from sklearn.metrics import confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns

print("\n" + "="*70)
print("ðŸŽ“ ML-BASED EARLY WARNING SYSTEM - DEMONSTRATION")
print("="*70)

# Load historical data
print("\nðŸ“Š STEP 1: LOADING HISTORICAL DATA")
print("-"*70)
df = pd.read_csv('data/historical/historical_students.csv')
print(f"âœ… Loaded {len(df)} historical students (2020-2024)")
print(f"\nðŸ“ˆ Outcome Distribution:")
print(df['outcome'].value_counts())
print(f"\n   â€¢ Graduated: {len(df[df['outcome']=='graduated'])} ({len(df[df['outcome']=='graduated'])/len(df)*100:.1f}%)")
print(f"   â€¢ Dropped Out: {len(df[df['outcome']=='dropped_out'])} ({len(df[df['outcome']=='dropped_out'])/len(df)*100:.1f}%)")
print(f"   â€¢ Still Active: {len(df[df['outcome']=='active'])} ({len(df[df['outcome']=='active'])/len(df)*100:.1f}%)")

# Analyze patterns
print("\n" + "="*70)
print("ðŸ” STEP 2: PATTERN ANALYSIS - WHY STUDENTS DROP OUT")
print("-"*70)

graduated = df[df['outcome'] == 'graduated']
dropped = df[df['outcome'] == 'dropped_out']

print("\nðŸ“Š COMPARISON: Graduated vs Dropped Out Students")
print("-"*70)

comparisons = {
    'Attendance Rate (%)': ('attendance_rate', '{:.1f}%'),
    'Engagement Score': ('engagement_score', '{:.1f}'),
    'Assignment Completion (%)': ('assignment_completion_rate', '{:.1f}%'),
    'Average GPA': ('avg_grade_points', '{:.2f}'),
    'Login Frequency (per week)': ('avg_login_count', '{:.1f}'),
    'Time on LMS (minutes)': ('time_spent_minutes', '{:.0f}'),
    'Consecutive Absences': ('consecutive_absences', '{:.0f}'),
}

for label, (col, fmt) in comparisons.items():
    grad_val = graduated[col].mean()
    drop_val = dropped[col].mean()
    diff = grad_val - drop_val
    print(f"\n{label}:")
    print(f"  Graduated:   {fmt.format(grad_val)}")
    print(f"  Dropped Out: {fmt.format(drop_val)}")
    print(f"  Difference:  {fmt.format(diff)} {'(HIGHER for graduates)' if diff > 0 else '(HIGHER for dropouts)'}")

# Load trained models
print("\n" + "="*70)
print("ðŸ¤– STEP 3: LOADING TRAINED ML MODELS")
print("-"*70)

dropout_model = joblib.load('models/dropout_risk_model_model_v2.pkl')
dropout_scaler = joblib.load('models/dropout_risk_model_scaler_v2.pkl')
dropout_features = joblib.load('models/dropout_risk_model_features_v2.pkl')

print(f"âœ… Loaded Dropout Risk Model (Random Forest)")
print(f"   â€¢ Features used: {len(dropout_features)}")
print(f"   â€¢ Top features: {', '.join(dropout_features[:5])}")

# Feature importance
print("\n" + "="*70)
print("ðŸŽ¯ STEP 4: FEATURE IMPORTANCE - WHAT MATTERS MOST")
print("-"*70)

importances = pd.DataFrame({
    'Feature': dropout_features,
    'Importance': dropout_model.feature_importances_
}).sort_values('Importance', ascending=False)

print("\nðŸ“Š Top 10 Most Important Features:")
print("-"*70)
for idx, row in importances.head(10).iterrows():
    bar = "â–ˆ" * int(row['Importance'] * 100)
    print(f"{row['Feature']:30s} {bar} {row['Importance']:.4f}")

# Make predictions on test students
print("\n" + "="*70)
print("ðŸ”® STEP 5: MAKING PREDICTIONS ON TEST STUDENTS")
print("-"*70)

# Prepare features
X = df[dropout_features].fillna(0).replace([np.inf, -np.inf], 0)
y_true = (df['outcome'] == 'dropped_out').astype(int)

# Scale and predict
X_scaled = dropout_scaler.transform(X)
y_pred = dropout_model.predict(X_scaled)
y_pred_proba = dropout_model.predict_proba(X_scaled)[:, 1]

# Calculate metrics
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

print(f"\nðŸ“Š MODEL PERFORMANCE METRICS:")
print("-"*70)
print(f"   Accuracy:  {accuracy_score(y_true, y_pred):.4f} ({accuracy_score(y_true, y_pred)*100:.2f}%)")
print(f"   Precision: {precision_score(y_true, y_pred):.4f}")
print(f"   Recall:    {recall_score(y_true, y_pred):.4f}")
print(f"   F1-Score:  {f1_score(y_true, y_pred):.4f}")
print(f"   ROC-AUC:   {roc_auc_score(y_true, y_pred_proba):.4f}")

print(f"\nðŸ’¡ What this means:")
print(f"   â€¢ The model correctly identifies {accuracy_score(y_true, y_pred)*100:.1f}% of students")
print(f"   â€¢ When it predicts dropout, it's right {precision_score(y_true, y_pred)*100:.1f}% of the time")
print(f"   â€¢ It catches {recall_score(y_true, y_pred)*100:.1f}% of actual dropout cases")

# Confusion Matrix
cm = confusion_matrix(y_true, y_pred)
print(f"\nðŸ“Š CONFUSION MATRIX:")
print("-"*70)
print(f"                    Predicted: Did Not Drop | Predicted: Dropped Out")
print(f"Actually Did Not Drop:  {cm[0][0]:6d}             |     {cm[0][1]:6d}")
print(f"Actually Dropped Out:   {cm[1][0]:6d}             |     {cm[1][1]:6d}")

print(f"\nðŸ’¡ Interpretation:")
print(f"   â€¢ True Negatives (Correct - Not at risk): {cm[0][0]}")
print(f"   â€¢ False Positives (False alarm): {cm[0][1]}")
print(f"   â€¢ False Negatives (Missed dropout): {cm[1][0]}")
print(f"   â€¢ True Positives (Correct - At risk): {cm[1][1]}")

# Example predictions
print("\n" + "="*70)
print("ðŸŽ¯ STEP 6: EXAMPLE PREDICTIONS")
print("-"*70)

# Show 3 high-risk students
df['dropout_probability'] = y_pred_proba
df['predicted_dropout'] = y_pred

high_risk = df[df['dropout_probability'] > 0.8].head(3)

print(f"\nðŸš¨ HIGH-RISK STUDENTS (Dropout Probability > 80%):")
print("-"*70)

for idx, student in high_risk.iterrows():
    print(f"\nStudent ID: {student['student_id']}")
    print(f"  Actual Outcome: {student['outcome']}")
    print(f"  Predicted Dropout Probability: {student['dropout_probability']*100:.1f}%")
    print(f"  Key Risk Factors:")
    print(f"    â€¢ Attendance: {student['attendance_rate']:.1f}%")
    print(f"    â€¢ Engagement: {student['engagement_score']:.1f}")
    print(f"    â€¢ Assignment Completion: {student['assignment_completion_rate']:.1f}%")
    print(f"    â€¢ Consecutive Absences: {student['consecutive_absences']}")
    
# Show 3 low-risk students
low_risk = df[df['dropout_probability'] < 0.2].head(3)

print(f"\nâœ… LOW-RISK STUDENTS (Dropout Probability < 20%):")
print("-"*70)

for idx, student in low_risk.iterrows():
    print(f"\nStudent ID: {student['student_id']}")
    print(f"  Actual Outcome: {student['outcome']}")
    print(f"  Predicted Dropout Probability: {student['dropout_probability']*100:.1f}%")
    print(f"  Positive Indicators:")
    print(f"    â€¢ Attendance: {student['attendance_rate']:.1f}%")
    print(f"    â€¢ Engagement: {student['engagement_score']:.1f}")
    print(f"    â€¢ Assignment Completion: {student['assignment_completion_rate']:.1f}%")

# Model validation
print("\n" + "="*70)
print("âœ… STEP 7: MODEL VALIDATION - DOES IT WORK?")
print("-"*70)

correct_predictions = (y_true == y_pred).sum()
total = len(y_true)

print(f"\nðŸ“Š Validation Results:")
print(f"   â€¢ Total Students: {total}")
print(f"   â€¢ Correct Predictions: {correct_predictions}")
print(f"   â€¢ Incorrect Predictions: {total - correct_predictions}")
print(f"   â€¢ Accuracy: {correct_predictions/total*100:.2f}%")

# Success stories
correct_dropout = ((y_true == 1) & (y_pred == 1)).sum()
correct_notdrop = ((y_true == 0) & (y_pred == 0)).sum()

print(f"\nðŸŽ¯ Breakdown:")
print(f"   â€¢ Correctly identified dropout risk: {correct_dropout}")
print(f"   â€¢ Correctly identified low risk: {correct_notdrop}")

print("\n" + "="*70)
print("ðŸŽ‰ DEMONSTRATION COMPLETE!")
print("="*70)

print(f"\nðŸ’¡ KEY TAKEAWAYS:")
print(f"   1. Model trained on 800 historical students with known outcomes")
print(f"   2. Achieved {accuracy_score(y_true, y_pred)*100:.1f}% accuracy in predictions")
print(f"   3. Most important factors: attendance, engagement, assignment completion")
print(f"   4. Can identify at-risk students BEFORE they drop out")
print(f"   5. Enables early intervention to help struggling students")

print(f"\nðŸ“ Next: Use this model to predict risk for current {df.shape[0]} students")
print("="*70 + "\n")
